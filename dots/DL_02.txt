[Q.] Deep Learning 이란 무엇인가요?

Deep Learning?
 - input set과 output set을 mapping하는 것을 학습(learn)하는 것
 - neural network에서 hidden layer를 많이 사용한 것을 'deep'한 network라고 함
 - deep한 network의 application을 'deep learning'이라고 함
 - 즉, deep learning이란 "hidden layer를 많이 사용한 neural network의 application"

Feedforward Neural Networks
 - a.k.a. 'Multilayer Perceptron(MLP)'
 - (keywords) Input Layer, Hidden Layer, Output Layer
 - (keywords) intercept, features, Error back propagation

Neural Network 3가지
 - ANN: Artificial Neural Network
 - RNN: Recurrent Neural Network
 - CNN: Convolutional Neural Network

------------------------------------------

ANN
 - Artificial Neural Network

NN
 - Neural Network
 - 연결된 layer들의 시리즈
 - one end: 관측치의 feature 
 - the other end: target value (e.g. class label)

Feedforward Neural Network
 - a.k.a. 'Multilayer Perceptron(MLP)'
 - [GOAL] output layer 값들이 target 값들과 일치시키는 것
 - (keywords) Forward-Propagation, Back-Propagation
 - (keywords) Update weights
 - (keywords) output과 target 비교

Feedforward NN 만들기(construction)
 1) hidden layer와 output layer의 모든 layer들마다
    각 layer에 추가할 unit의 갯수와 activation function을 정의한다.
 2) network에서 사용할 hidden layer의 갯수를 정의한다.
  - layer 갯수가 많을수록 network가 더 복잡한 relationship을 학습
  - but, layer 갯수가 많을수록 동시에 computational cost가 커짐
 3) (필요시) output layer의 activation function 구조를 정의한다.
 4) loss function을 정의한다.
  - loss function: 얼마나 예측값이 실제값과 match하는지를 측정하는 함수
 5) optimizer를 정의한다.
  - 'walking around' the loss function
 6) performance를 evaluate할 metric을 하나 이상 정의/선택한다.
  - e.g.) accuracy

Feedforward NN의 구성요소 (details)
 - [A] Hidden Layers
 - [B] Output Layer
 - [C] Loss Function
 - [D] Optimizer

[A] Hidden Layers의 각 Unit
 - 1) 많은 input을 받는다.
 - 2) parameter 값에 따라서 각각의 input에 weight를 준다.
 - 3) weighted input 값들을 모두 합한다. (bias 포함)
 - 4) activate function을 적용한다.
 - 5) 자신(unit)의 output의 다음 layer의 unit에게 전달한다.

[B] Output Layer Pattern
 - 1) Binary Classification
   >> unit 하나 & sigmoid activation function
 - 2) Multi-class Classification
   >> k unit & softmax activation function
   >> k: target 클래스의 갯수
   >> softmax: (0,1) 구간의 확률분포로 normalize 해주는 역할
 - 3) Regression
   >> unit 하나 & no activation function

[C] Loss Function
 - 1) Binary Classification
   >> target class가 2개인 classification problem
   >> Loss Function: 'Cross-Entropy'
   >> also a.k.a Logarithmic loss
 - 2) Multiclass Classification
   >> target class가 2개 보다 많은 classification problem
   >> Loss Function: 'Categorical Cross-Entropy'
 - 3) Regression
   >> real-value quantity를 예측(predict)하는 problem
   >> Loss Function: Mean Squared Error(MSE)

[D] Optimizers
 - Stochastic gradient descent
 - Stochastic gradient descent with momentum 
 - Root mean square propagation
 - Adaptive moment estimation

------------------------------------------

RNN
 - Recurrent Neural Network

Problem
 - 매 point마다 이전 단어에 기반해서 다음 단어를 예측하는 문제

RNN 특징
 - Feedforward NN과 비슷
 - Feedforward NN과 다른 점: RNN에는 feedback loop가 있다
 - feedback loop가 있다는 것의 의미
   >> 이전(previous) step들의 특징을 현재(current) step에 반영!
 - 이러한 feedback loop를 가지는 RNN의 architecture는 시퀀스(순서형 정보)를 생성함
 - 상황을 시뮬레이션하고 종합적인 데이터를 생성하는 시퀀스를 생성
 - sequence data 모델링에 이상적임
 - sequence data 예시) speech text mining, image captioning, time series prediction, robot control, langauge modeling 등
 - [RNN의 핵심] 
   >> Output layer -> Hidden layer로 피드백
   >> Hidden layer -> 이전 Hidden layer로 피드백
   >> Hidden layer -> Input layer로 피드백

RNN의 단점
 - Memory heavy: 메모리를 많이 사용한다.
 - long-term temporal dependency를 학습하기 어렵다.
  >> e.g.) 장문의 context

LSTM
 - Long Short Term Memory (LSTM)
 - RNN의 LTD 단점을 보완하기 위해 고안된 architecture
 - long-range dependency를 가능하게 함

LSTM 구조
 - linear한 memory cell을 사용하여 더 잘 기억할 수 있도록 한다.
 - linear memory cell들은 gate unit 세트로 둘러싸여 있음.
 - gate unit들은 정보의 흐름을 control함.
 - 정보의 흐름 examples
   >> 언제 정보가 memory에 들어올지, 언제 정보를 잊어버릴지, 언제 정보를 내보낼지 등
 - recurrent component에서 activation function은 사용하지 않으므로, 
   back propagation을 하더라도 gradient term이 사라지지(vanish) 않는다.

RNN vs. LSTM
 - RNN: RNN의 반복되는 module은 single layer를 내포한다.
 - LSTM: LSTM의 반복되는 module은 4개의 interacting layer들을 내포한다.
   >> interacting layer들: activation function 통과하지 않음!

------------------------------------------

CNN
 - Convolutional Neural Network

Feedforward NN의 한계점?
 - pixel과 같은 spatial structure에 적용하기 어렵다.
 - local 패턴보다 global 패턴을 학습하다 보니 사진에 있는 객체와 같은 특정 부분의 탐지가 어렵다.
 - 즉, 이미지에서 특정 object가 어디에서 나타나든 탐지가 어렵다.
 - 따라서 이미지 분석에 특화된 NN 솔루션이 필요 -> CNN.

Convolutional Neural Network 특징
 - so called 'ConvNet', or 'CNN'
 - 이미지를 인풋으로 받을 수 있고 이미지 속의 다양한 aspect/object들에 중요도(가중치)를 줄 수 있는 DL 알고리즘
 - 여러가지 서로 다른 객체들을 구분할 수도 있음.

CNN의 특징(이어서)
 - input은 이미지(tensor)여야 함 (assumption)
 - 이 assumption은 CNN을 최적화시키고 다른 NN과의 차이를 만드는 부분임.
 - 다른 classification 알고리즘들에 비해 전처리량이 비교적 적다.
 - computer vision에 매우 효과적인 것으로 증명되었음.
   (e.g. recognizing cats, dogs, planes and hot dogs)

CNN의 특징(이어서) 
 - relevant filter들을 활용해서 Spatial(공간적인) & Temporal(일시적인) dependency를 캡처할 수 있음.
 - filter들 예시: 가로선을 찾는 filter, 세로선을 찾는 filter, 등
 - 이미지 데이터셋에 보다 잘 fit된다.
   >> 포함된 parameter 갯수가 줄어들고 weight를 재사용할 수 있기 때문.
 - 즉, CNN은 이미지의 복잡함을 이해하도록 학습(train)될 수 있음

CNN 핵심 개념(key concepts)
[1] Convolutional Layer (CONV Layer)
 - 학습 filter들 set
 - 이 filter들은 spacial 특징들을 잡아내는 역할
 - output: 각각의 filter들로부터 나온 2차원 activation map들이 stacked된 결과
[2] Pooling Layer (POOL Layer)
 - spatial size와 parameter 개수를 줄여주기 위한 down-sampling layer
 - 이 pooling layer 또한 overfitting을 조절하는 역할을 돕는다.
 - POOL Layer는 CONV Layer들 사이에 insert해준다.
 - down-sampling을 할 때에 사용하는 함수들 e.g.) max, average, L2-norm
[3] Fully Connected Layer (FC Layer)
 - 이전 layer에 있는 모든 뉴런과 연결되어 있는 layer
 - classification task를 수행하는 것을 돕는다.
[4] Parameter Sharing
 - CONV layer 이외에 CNN의 또 하나 특징으로 parameter sharing이 있음.
 - CONV layer는 filter들마다 같은 weight(가중치) set을 사용한다.
 - 따라서 전체적으로 필요한 parameter 수를 줄일 수 있게 됨.

Convolution operation의 목적
 - high-level feature를 추출(extract)하는 것
 - high-level feature 예시) input 이미지의 edge들
 - ConvNets에서 CONV Layer가 하나만 있어야 할 필요는 없다.
 - 다만, 첫번째 CONV Layer가 low-level feature들을 잡아내는(capture) 역할을 함.
 - low-level feature 예시) edges, color, gradient orientation 등
 - layer가 추가될 수록 architecture가 high-level feature에 adapt함.
   >> (마치 인간이 인지하는 것처럼) 데이터셋의 이미지에 대한 총체적인 이해를 가진 network를 리턴.

Convolution operation의 결과 2가지 경우
1) Same Padding
 - convolve된 feature의 dimensionality는 그대로이거나 증가.
 - 즉, input layer에 비해 feature가 많아지는 것(정보가 많아지는 것)
2) Valid Padding
 - convolve된 feature의 dimensionality가 input layer보다 감소.







