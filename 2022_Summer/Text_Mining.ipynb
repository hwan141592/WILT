{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4641519-5773-4f88-ac1d-4138fc70bc9c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a34706a-48a1-40cd-b53f-fd0c5588d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/hwan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Statistics skills, and programming skills are equally important for analytics. Statistics skills, and domain knowledge are important for analytics. I like reading books and travelling.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')        # once is enough\n",
    "nltk.download('stopwords')    # once is enough\n",
    "# stopwords.words('english')[0:10]\n",
    "\n",
    "text = 'Statistics skills, and programming skills are equally important for analytics. Statistics skills, and domain knowledge are important for analytics. I like reading books and travelling.'\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29358cf0-eecd-4df6-86d5-d8c22d67b59a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cab519b1-fe97-42bb-a006-cb6f09c1a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Function to remove punctuations\n",
    "def remove_punctuations(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    punt_removed= [w for w in words if w.lower() not in string.punctuation]\n",
    "    return \" \".join(punt_removed)\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(text, lang='english'):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lang_stopwords= stopwords.words(lang)\n",
    "    stopwords_removed= [w for w in words if w.lower() not in lang_stopwords]\n",
    "    return \" \".join(stopwords_removed)\n",
    "\n",
    "# Function to remove whitespace\n",
    "def remove_whitespace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f5a2360-80be-48d2-bd24-043383cbccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, lang='english'):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    punt_removed= [w for w in words if w.lower() not in string.punctuation]\n",
    "    text = \" \".join(punt_removed)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lang_stopwords= stopwords.words(lang)\n",
    "    stopwords_removed= [w for w in words if w.lower() not in lang_stopwords]\n",
    "    text = \" \".join(stopwords_removed)\n",
    "    return \" \".join(text.split())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f4dae42-fdee-43c7-b8e0-2337fc21b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statistics skills programming skills equally important analytics statistics skills domain knowledge important analytics like reading books travelling'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text(text_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ebc8e-30b1-4ccb-9dba-fdad7000262a",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "427dfdfb-68cf-4219-b0b3-09c60ed9635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistics', 'skills', 'programming', 'skills', 'equally']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(text_processed)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bba92-0bf8-4f8f-80c8-c49160f292d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (REF.) Small Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d792f-a5ab-4ae8-b61f-d7bf8a52301d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "070d4330-54d7-4366-a7bb-686096b4fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e5cebc-e435-4373-9c2f-cd538ee55c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Statistics skills, and programming skills are equally important for analytics.',\n",
       " 'Statistics skills, and domain knowledge are important for analytics.',\n",
       " 'I like reading books and travelling.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and tokenize\n",
    "text = 'Statistics skills, and programming skills are equally important for analytics. Statistics skills, and domain knowledge are important for analytics. I like reading books and travelling.'\n",
    "sent_tokenize_list = sent_tokenize(text)\n",
    "sent_tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382042e0-06c8-4cfe-843f-d5c9ed588402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Statistics', 'skills', ',', 'and', 'programming', 'skills', 'are', 'equally', 'important', 'for', 'analytics.', 'Statistics', 'skills', ',', 'and', 'domain', 'knowledge', 'are', 'important', 'for', 'analytics.', 'I', 'like', 'reading', 'books', 'and', 'travelling', '.']\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Create text and tokenize\n",
    "text='Statistics skills, and programming skills are equally important for analytics. Statistics skills, and domain knowledge are important for analytics. I like reading books and travelling.'\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef88eb9-2270-4247-9c68-f81b3eb4420e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4f1b0fd-a991-4327-96f8-c7b347f68dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6397d00-1e25-4fcc-bbbb-0647a7d63a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')        # once is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8ed1936-a0ca-49cd-a449-2fdd5f47ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hwan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')    # once is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75c49b41-2277-48ed-ba6a-b26f3bec2896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample English sentence with 3 whitespaces , carriage return \\n number 1234, tab \\t, stop words and punctuations!'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "\n",
    "# nltk.download('punkt')        # once is enough\n",
    "# nltk.download('stopwords')    # once is enough\n",
    "\n",
    "# Create text\n",
    "text = \"This is a sample English sentence with 3 whitespaces , carriage return \\n number 1234, tab \\t, stop words and punctuations!\"\n",
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5685b332-8933-4194-a7bb-7d4f56ec5e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample English sentence with  whitespaces , carriage return \\n number , tab \\t, stop words and punctuations!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Remove numbers\n",
    "remove_numbers(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc5a9109-9663-4d32-8172-36b2d7743d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample English sentence with 3 whitespaces carriage return number 1234 tab stop words and punctuations'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove punctuations\n",
    "def remove_punctuations(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    punt_removed= [w for w in words if w.lower() not in string.punctuation]\n",
    "    return \" \".join(punt_removed)\n",
    "\n",
    "# Remove punctuations\n",
    "remove_punctuations(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "486bbc07-4d14-4776-80a5-06aae0111b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample English sentence 3 whitespaces , carriage return number 1234 , tab , stop words punctuations !'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove stop words\n",
    "def remove_stopwords(text, lang='english'):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lang_stopwords= stopwords.words(lang)\n",
    "    stopwords_removed= [w for w in words if w.lower() not in lang_stopwords]\n",
    "    return \" \".join(stopwords_removed)\n",
    "\n",
    "# Remove stop words\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe4749d9-80a4-44d3-b0b9-d289c61d034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample English sentence with 3 whitespaces , carriage return number 1234, tab , stop words and punctuations!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove whitespace\n",
    "def remove_whitespace(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Remove white space including space, tab and carriage return\n",
    "remove_whitespace(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1f69c99-5550-400f-9bdc-b4e0df15533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample English sentence with 3 whitespaces , carriage return number 1234, tab , stop words and punctuations!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processed = remove_whitespace(text)\n",
    "text_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
